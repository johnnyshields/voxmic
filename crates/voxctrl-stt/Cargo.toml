[package]
name = "voxctrl-stt"
version = "0.2.0"
edition = "2021"
description = "Heavy ML inference backends — whisper-native, whisper-cpp, voxtral-native"

[features]
default = ["stt-voxtral-native", "stt-whisper-native"]

# STT backends
stt-whisper-cpp     = ["dep:whisper-rs"]
stt-whisper-native  = ["dep:candle-core", "dep:candle-nn", "dep:candle-transformers", "dep:hf-hub", "dep:tokenizers"]
stt-voxtral-native  = ["dep:voxtral-mini-realtime", "dep:burn"]

# GPU acceleration (opt-in, cross-cutting)
cuda = []

[dependencies]
voxctrl-core = { path = "../voxctrl-core", default-features = false }

anyhow     = "1"
log        = "0.4"
hound      = "3.5"
serde_json = "1"

# STT: whisper-cpp (optional)
whisper-rs = { version = "0.15", optional = true }

# STT: candle native (optional)
candle-core         = { version = "0.8", optional = true }
candle-nn           = { version = "0.8", optional = true }
candle-transformers = { version = "0.8", optional = true }
hf-hub              = { version = "0.3", optional = true }
tokenizers          = { version = "0.20", optional = true }

# STT: voxtral-native (optional) — pure Rust Voxtral via Burn ML framework
voxtral-mini-realtime = { git = "https://github.com/TrevorS/voxtral-mini-realtime-rs", default-features = false, features = ["hub", "native-tokenizer", "wgpu"], optional = true }
burn = { version = "0.20", default-features = false, features = ["wgpu"], optional = true }
